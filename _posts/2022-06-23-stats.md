---
layout: post
title: Notes on Inferences for Regression
tags: mathjax stats
math: true
toc: true
date: 2022-06-23 20:50 +0800
---

Peer tutoring materials

Updated: 20 April 2022

---

### Population regression line

Calculated from **every value in the population**: \\\(\mu_y = \beta_0+\beta_1 x\\\)

### Sample regression line

Calculated from **a particular sample**: \\\(\hat y=b_0+b_1x\\\)

### Sampling distribution of sample slope

Shows **the pattern of variation in the sample slope** \\\(b_1\\\)

- Simple random sample: \\\(n\\\) out of \\\(N\\\) observations
- Response value: \\\(y\\\)
- Explanatory value: \\\(x\\\)
- Shape: approximately normal, if the **Normal** condition is met
- Center: \\\(\mu_{b_1}=\beta_1\\\), where \\\(b_1\\\) is an **unbiased estimator** of \\\(\beta_1\\\)
- \\\(10\% \\\) condition: \\\(n<0.1N\\\)
- Variability/Standard deviation: \\\(\sigma_{b_1}=\frac{\sigma}{\sigma_x\sqrt{n}}\\\), where \\\(\sigma\\\) is **the SD of response variable** and \\\(\sigma_x\\\) is **the SD of explanatory variable**

### Regression inference (LINER)

- Linear relationship between \\\(x\sim y\\\)
- Observations are independent of each other (check 10% condition when w/o replacement)
- Normal: \\\(y\\\)-value varies according to a normal distribution as \\\(x\\\)-value is fixed
- Equal SD: \\\(\sigma\\\) is always the same for all values of \\\(x\\\)
- Random sample obtained
- Interpretation:
  - Linear: The **scatter plot** of $y$ versus $x$ shows a linear form and there is no pattern in the residual plot.
  - Independent: Since the experiment is done randomly (and no objects are used twice), knowing the result of one observation should not help us predict the value of another observation.
  - Normal: There is no strong skewness or outliers in the histogram of residuals.
  - Equal SD: Similar amount of scatter about the \\\( \text{residual}=0\\\) line. However, the residual seems to vary more at (what \\\(x\\\) values).
  - Random: The experiment objects are randomly assigned.

- `Estimating parameters`

  - `Standard error` shows **how far the sample slope typically varies from the true populational slope if we repeat the data production/random assignments many times**:  $SE_{b_1}=\frac{s}{s_x \sqrt{n-1}} $

  - Read out data from the `calculator table`:

    - `Constant Coef` is $b_0$: To wit to interpret the $y-intercept$, ... **on average**.
    - `x's Coef (Drop height)` is $b_1$: For an increase of 1 unit of the $x-value$, the **average** $y-value$ increases by ... unit.
    - `s value` is  $\sigma $: The actual  $y-value $ typically varies by about  $\sigma $ units from the predicted with the LSRL using $x=(explanatory\ variable\ name)$.
    - `SE value` is  $SE_{b_1}$: if we **repeat the data production/random assignments many times**, the sample slope typically varies by about $SE_{b_1}$ units from the true population slope for predicting $y-value$ from $x-value$.

- `Confidence interval of the slope`   $\text{t-interval}=b_1\pm t^{\*}\cdot SE_{b_1}; \text{df}(t^{\*})=n-2 $

  - Useful templates:
    - State: ...% CI for slope  $\beta $, where
      $\beta$
    is the true slope of the population regression line relating  $y-value$ to  $x-value$.
    - Plan: Linear regression t-interval for  $\beta$. LINER!
    - Do: CI formula, df, t*  $\to$ $CI\in(a,b)$
    - Conclude: We are CI% confident that the CI from ... to ... captures the true slope of the regression line relating  $y-value$ to  $x-value$.

- `Significant test for the slope`

  - The standardized test statistic  $t=\frac{b_1-\text{hypothesize slope}}{SE_{b_1}} $

  - Useful templates:

    - State: We want to test $H_0:\beta _1 =\text{hypothesized slope}\\ H_0:\beta _1 > \text{hypothesized slope}$
          where $\beta$ is the true slope of the population regression line relating $y-value$ to $x-value$ **at the confidence level $\alpha = 0.05$**.

    - Plan: Linear regression t-test for $\beta$. LINER!

    - Do: t-statistic formula, df $\to$  $t-statistic$;
     t-cdf  $\to p-value$

    - Conclude: Compare the  $p-value$ 
     to  $\alpha$.

      - Fail to reject $H_0$, there is no convincing evidence that $H_a$ is true.
      - Reject $H_0$, there is convincing evidence that $H_a$ is true.
